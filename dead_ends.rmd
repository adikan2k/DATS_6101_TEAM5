---
title: "Dead_Ends"
author: "Team5"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# ***Dead Ends and Data Trends: A Journey Through America's Recent Accident Stats***
# An insightful journey into understanding the patterns behind road fatalities in the U.S. 
# and creating actionable insights for a safer future.

# Project Overview
# Motor vehicle accidents are a leading cause of unintentional injury-related deaths in the U.S. 
# Using the 2022 FARS dataset, our analysis focuses on revealing trends and risk factors that contribute to fatal crashes.

```{r, include=T, results='markup',message=TRUE}
# Loading the necessary libraries
library(dplyr)
library(tidyr)
library(stringr)

# Loading the dataset
dataset <- read.csv("dataset.csv")

# Now viewing the structure of the dataset
str(dataset)
summary(dataset)
```

# Now, we check for duplicate rows. Let's clear them out!
```{r, include=T, results='markup',message=TRUE}
dataset <- dataset %>% distinct()
```

```{r, include=T, results='markup',message=TRUE}

library(dplyr)
dataset <- dataset %>% select(-x, -y, -STATE, -CITY, -COUNTY, -MONTH, -DAYNAME, -DAY_WEEK, -MINUTENAME, -TWAY_ID2, -ROUTE, -RUR_URB, -FUNC_SYS, -RD_OWNER, -NHS, -SP_JUR, -LATITUDENAME, -LONGITUDNAME, -MILEPT, -HARM_EV, -MAN_COLL, -MILEPTNAME, -RELJCT1, -RELJCT2, -TYP_INT, -REL_ROAD, -WRK_ZONE, -LGT_COND, -WEATHER, -SCH_BUS, -RAIL, -NOT_MIN, -ARR_MINNAME, -ARR_HOUR, -HOSP_MN, -SCH_BUSNAME, -RAILNAME, -PERNOTMVIT, -VE_FORMS, -PERSONS)
colnames(dataset)

# Lets rename columns for consistency
```{r, include=T, results='markup',message=TRUE}
names(dataset) <- str_to_lower(names(dataset))
names(dataset) <- str_replace_all(names(dataset), " ", "_")
```

# Saving the new cleaned dataset
```{r, include=T, results='markup',message=TRUE}
write.csv(dataset, "NEW_dataset.csv", row.names = FALSE)
```





